{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01351751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ibmqfactory.load_account:WARNING:2021-06-05 00:08:53,853: Credentials are already in use. The existing account in the session will be replaced.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend in use:  ibmq_manila\n",
      "Qubits currently in use:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Daniel\\anaconda3\\envs\\scix\\lib\\site-packages\\ipykernel_launcher.py:51: DeprecationWarning: Passing a Qobj to Backend.run is deprecated and will be removed in a future release. Please pass in circuits or pulse schedules instead.\n"
     ]
    }
   ],
   "source": [
    "# Adaption of a notebook which is an amalgamation of the hybrid qantum-classical neural network code from the Qiskit textbook, Georgina Carson and Samuel Wait's miscellaneous code, with some modification by me (Daniel Duncan) for the sake of data collection automation and ease of variable manipulation.\n",
    "\n",
    "import qiskit\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from qiskit import IBMQ\n",
    "from qiskit import transpile, assemble\n",
    "from qiskit.visualization import *\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Function\n",
    "\n",
    "from IPython.display import FileLink\n",
    "\n",
    "trials = 1\n",
    "qubitsToUse = 5\n",
    "\n",
    "# load IBM Q account\n",
    "# IBMQ.save_account('')\n",
    "provider = IBMQ.load_account()\n",
    "backend = provider.backend.ibmq_manila\n",
    "\n",
    "# quantum circuit\n",
    "class QuantumCircuit:\n",
    "    def __init__(self, n_qubits, backend, shots):\n",
    "        self._circuit = qiskit.QuantumCircuit(n_qubits)\n",
    "\n",
    "        # all qubits in machine\n",
    "        allQubits = [i for i in range(n_qubits)]\n",
    "        # theta parameter\n",
    "        self.theta = qiskit.circuit.Parameter('theta')\n",
    "\n",
    "        # circuit itself\n",
    "        self._circuit.h(allQubits)\n",
    "        self._circuit.barrier()\n",
    "        self._circuit.ry(self.theta, allQubits)\n",
    "        # measure qubits\n",
    "        self._circuit.measure_all()\n",
    "\n",
    "        self.backend = backend\n",
    "        self.shots = shots\n",
    "    \n",
    "    def run(self, thetas):\n",
    "        t_qc = transpile(self._circuit, self.backend)\n",
    "        qobj = assemble(t_qc, shots=self.shots, parameter_binds = [{self.theta: theta} for theta in thetas])\n",
    "        job = self.backend.run(qobj)\n",
    "        result = job.result().get_counts()\n",
    "        \n",
    "        counts = np.array(list(result.values()))\n",
    "        states = np.array(list(result.keys())).astype(float)\n",
    "        \n",
    "        # Compute probabilities for each state\n",
    "        probabilities = counts / self.shots\n",
    "        # Get state expectation\n",
    "        expectation = np.sum(states * probabilities)\n",
    "        \n",
    "        return np.array([expectation])\n",
    "\n",
    "# hybrid function\n",
    "class HybridFunction(Function):\n",
    "    # forward pass\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, quantum_circuit, shift):\n",
    "        ctx.shift = shift\n",
    "        ctx.quantum_circuit = quantum_circuit\n",
    "\n",
    "        expectation_z = ctx.quantum_circuit.run(input[0].tolist())\n",
    "        result = torch.tensor([expectation_z])\n",
    "        ctx.save_for_backward(input, result)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    # backward pass\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, expectation_z = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "\n",
    "        shift_right = input_list + np.ones(input_list.shape) * ctx.shift\n",
    "        shift_left = input_list - np.ones(input_list.shape) * ctx.shift\n",
    "\n",
    "        gradients = []\n",
    "        for i in range(len(input_list)):\n",
    "            expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "            expectation_left = ctx.quantum_circuit.run(shift_left[i])\n",
    "\n",
    "            gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "            gradients = np.array([gradients]).T\n",
    "            return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "class Hybrid(nn.Module):\n",
    "    def __init__(self, backend, shots, shift):\n",
    "        super(Hybrid, self).__init__()\n",
    "        self.quantum_circuit = QuantumCircuit(qubitsInUse, backend, shots)\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, input):\n",
    "        return HybridFunction.apply(input, self.quantum_circuit, self.shift)\n",
    "\n",
    "# first 100 samples\n",
    "n_samples = 100\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_train.targets == 0) [0][:n_samples], np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)\n",
    "n_samples_show = 5\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0].numpy().squeeze(), cmap='gray')\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets.item()))\n",
    "\n",
    "    n_samples_show -= 1\n",
    "\n",
    "n_samples = 100\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(256, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.hybrid = Hybrid((backend), 8192, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.hybrid(x)\n",
    "        return torch.cat((x, 1 - x), -1)\n",
    "\n",
    "\n",
    "# outputs the name of the device\n",
    "print(\"Backend in use: \", backend.name())\n",
    "\n",
    "accuracyPlural = []\n",
    "qubitsUsed = []\n",
    "\n",
    "for i in range(trials):\n",
    "    for qubitsInUse in range(qubitsToUse):\n",
    "        qubitsInUse = qubitsInUse + 1\n",
    "        qubitsUsed.append(qubitsInUse)\n",
    "        print(\"Qubits currently in use: \", qubitsInUse)\n",
    "        circuit = QuantumCircuit(qubitsInUse, backend, 8192)\n",
    "        circuit._circuit.draw()\n",
    "\n",
    "        optimizer = optim.Adam(Net().parameters(), lr=0.001)\n",
    "        loss_func = nn.NLLLoss()\n",
    "\n",
    "        epochs = 2\n",
    "\n",
    "        loss_list = []\n",
    "        model = Net()\n",
    "        model.train()\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = []\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                # forward pass\n",
    "                output = model(data)\n",
    "                # calculating loss\n",
    "                loss = loss_func(output, target)\n",
    "                # backward pass\n",
    "                loss.backward()\n",
    "                # optimise weights\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss.append(loss.item())\n",
    "            loss_list.append(sum(total_loss)/len(total_loss))\n",
    "            print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(100. * (epoch + 1) / epochs, loss_list[-1]))\n",
    "        plt.plot(loss_list)\n",
    "        plt.title('Training Convergence')\n",
    "        plt.xlabel('Training Iterations')\n",
    "        plt.ylabel('Neg Log Likelihood Loss')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            correct = 0\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                output = model(data)\n",
    "\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "                loss = loss_func(output, target)\n",
    "                total_loss.append(loss.item())\n",
    "                accuracy = correct / len(test_loader) * 100\n",
    "            print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(sum(total_loss) / len(total_loss), accuracy))\n",
    "        accuracyPlural.append(accuracy)\n",
    "        n_samples_show = 5\n",
    "        count = 0\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(test_loader):\n",
    "                if count == n_samples_show:\n",
    "                    break\n",
    "                output = model(data)\n",
    "\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "\n",
    "                axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "                axes[count].set_xticks([])\n",
    "                axes[count].set_yticks([])\n",
    "                axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "\n",
    "                count += 1\n",
    "\n",
    "qubitsExport = {i: qubitsUsed[i] for i in range(len(qubitsUsed))}\n",
    "accuracyExport = {i: accuracyPlural[i] for i in range(len(accuracyPlural))}\n",
    "i = i + 1\n",
    "\n",
    "# function to export your data as a CSV (you can then use in Excel or any programming language you like)\n",
    "def export_dict(filename, dict):\n",
    "    with open(filename, 'w') as f:\n",
    "        w = csv.DictWriter(f, dict.keys())\n",
    "        w.writeheader()\n",
    "        w.writerow(dict)\n",
    "    local_file = FileLink(filename, result_html_prefix=\"Click here to download: \")\n",
    "    display(local_file)\n",
    "\n",
    "export_dict('qubits.csv', qubitsExport)\n",
    "export_dict('accuracies.csv', accuracyExport)\n",
    "print(\"Experiment complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afc7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}